---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ggs-dataprep-script
  labels:
    app: ggs
data:
  generate_sas_token.py: |
   from datetime import datetime, timedelta
   from azure.storage.blob import BlobServiceClient, generate_account_sas, ResourceTypes, ContainerSasPermissions,generate_container_sas
   from azure.storage.blob import BlobClient
   import os
   import sys   
   
   account=sys.argv[1]
   container=sys.argv[2]
   key=sys.argv[3]
   
   sas_token = generate_container_sas(        
        account_name=account,
        container_name=container,
        account_key=key,
        permission=ContainerSasPermissions(read=True),
        expiry=datetime.utcnow() + timedelta(hours=1)
    )
    
   print(sas_token)
    
  install.sh: |
    #!/bin/bash

    ## Generate SAS Token from storage account key, 
    ## If you already have a SAS Token than set it directly
    SAS_TOKEN=$(python3 generate_sas_token.py $STORAGE_ACCOUNT $STORAGE_CONTAINER $STORAGE_ACCOUNT_KEY)

    rm -rf $GGS_DATA/*
    LOCAL_ZIP_DIR=/usr/local/ggs/ggs-zip
    mkdir -p $LOCAL_ZIP_DIR
    # copy spds locally
    cat $SPD_LIST/spd.list | xargs -I spd azcopy copy spd$SAS_TOKEN $LOCAL_ZIP_DIR

    # create destination directory and extract datasets
    mkdir -p $GGS_DATA
    cd /usr/local/ggs/cli
    sh ./cli.sh extract  --s $LOCAL_ZIP_DIR --d $GGS_DATA

    # clean up
    rm -rf $LOCAL_ZIP_DIR
